<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
                    
        <head><meta content="application/xhtml+xml; charset=utf-8" http-equiv="Content-Type"/>
            <meta content="application/xhtml+xml; charset=utf-8" name="content-type"/>
            <meta content="Scalability and Deployment" name="title"/>
            <meta content="Sebastian Springer" name="author"/>
            <meta content="Rheinwerk Publishing" name="publisher"/>
            <meta content="© 2022 by Rheinwerk Publishing Inc., Boston (MA)" name="copyright"/>
            <meta content="Node.js - The Comprehensive Guide - Scalability and Deployment" name="description"/>
            <meta content="en" name="language"/>
            <title>Scalability and Deployment</title>
            <link href="common/main.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000029756394" name="Adept.expected.resource"/>
        </head>
    


                    <body class="office_us type_kapitel">
                        <div id="main">
        <h2 class="t2" id="h25.3">25.3    Scaling<a class="indexanchor" id="i25_51"/></h2>
        <p class="standard">An important criterion in the development and stabilization of Node.js is the performance aspect<a class="indexanchor" id="i25_52"/>. A declared goal of the platform’s developers is to provide developers with a very powerful tool that can be used to easily implement stable and performant applications. The number of requests and also the amount of data that can be served by an instance of an application aren’t unlimited but depend on numerous external and internal factors. The things that you as a developer can directly influence primarily concern the way you design your application. This includes, for example, the design of the source code in general, that is, whether you generally pay attention to performance.</p>
        <p class="standard"><a id="p722"/>The following aspects have a potentially negative impact on the performance of an application:</p>
        <ul>
            <li>
                <p class="standard first-item last-item">Additional abstraction layers<a class="indexanchor" id="i25_53"/> such as frameworks or object-relational mapping (ORM) systems for databases</p>
            </li>
            <li>
                <p class="standard first-item last-item">Blocking operations<a class="indexanchor" id="i25_54"/> that cause you to wait for other systems or input</p>
            </li>
            <li>
                <p class="standard first-item last-item">Excessive complexity<a class="indexanchor" id="i25_55"/> of the source code</p>
            </li>
            <li>
                <p class="standard first-item last-item">A large number of search and read operations<a class="indexanchor" id="i25_56"/></p>
            </li>
        </ul>
        <p class="standard">On the other hand, you have the possibility to positively influence the performance of your application with various countermeasures:</p>
        <ul>
            <li>
                <p class="standard first-item last-item">Caching layers<a class="indexanchor" id="i25_57"/> to answer frequent requests directly</p>
            </li>
            <li>
                <p class="standard first-item last-item">Asynchronicity<a class="indexanchor" id="i25_58"/> to prevent operations from being blocked</p>
            </li>
            <li>
                <p class="standard first-item last-item">Pregeneration<a class="indexanchor" id="i25_59"/> of responses</p>
            </li>
        </ul>
        <p class="standard">Influencing factors that aren’t directly related to your application are, for example, the available resources, that is, free RAM or access to the processor. The fewer resources you have available, the more problematic the situation. What you should also consider is the throughput of write operations. For example, if you develop an application that needs to persist a lot of data, you should make sure to provide a system that can handle the expected amount of data. Here, the range extends from memory-based solutions such as Redis<a class="indexanchor" id="i25_60"/> to storage on the hard disk to storage solutions in the network, whereby write operations to the main memory are considerably faster than those to remote media via the network.</p>
        <p class="standard">No matter how many resources you can make available on one system, with a steadily growing number of users, you’ll eventually reach the limits of the most powerful server system, or upgrading a server will become disproportionately expensive at some point. In the following sections, you’ll learn how you can make sure that your application remains usable despite dwindling resources and an ever-increasing number of users. The solution to this problem can be found in a solid scaling strategy for your platform. As with deployment, depending on how large your application as well as your budget is, you can resort to a wide variety of solution strategies. First, you’ll now learn about strategies that focus on one system and provide for the use of multiple processor cores. After that, you’ll learn how to distribute your application across multiple systems using load balancing<a class="indexanchor" id="i25_61"/> or cloud solutions<a class="indexanchor" id="i25_62"/>.</p>
        
            <h3 class="t3" id="h25.3.1">25.3.1    Child Processes<a class="indexanchor" id="i25_63"/></h3>
            <p class="standard">Node.js follows the approach that the actual code of your application is executed in only one process. For a user accessing the system, this doesn’t cause any problem yet. The way Node.js handles processor resources doesn’t become relevant until multiple requests are made to the application in parallel or you have tasks within your application <a id="p723"/>that are very CPU-intensive and block other tasks. This is where the event-driven approach of JavaScript and Node.js comes into play. With the <samp class="listingcharacter listingcharacter">child_process</samp><a class="indexanchor" id="i25_64"/> module, you have a tool to ensure that your server resources are better utilized. You’ve already learned about the capabilities of the <samp class="listingcharacter listingcharacter">child_process</samp> module in <span class="crossreference "><a href="16_001.html#h16">Chapter 16</a></span>. The following sections provide a brief summary and some advice on how you can successfully parallelize subtasks in your application using JavaScript.</p>
            <p class="standard">The <samp class="listingcharacter listingcharacter">child_process</samp> module provides several methods that can be used to complete tasks separated from the main process. The most important method in this context is the <samp class="listingcharacter listingcharacter">fork</samp> method. This method enables you to create a standalone worker process<a class="indexanchor" id="i25_65"/> that can exchange messages with its parent process via a bidirectional communication link. This communication works on the basis of events. This means you can bind a callback function to an event that is triggered by the parent or child process, respectively. As its first argument, the <samp class="listingcharacter listingcharacter">fork</samp> method receives the path to a module to be executed within the child process. This means the source code of the child process should be located in a separate file. When you develop processes that run in parallel, the <samp class="listingcharacter listingcharacter">child_process</samp> module doesn’t provide much support. You have to take care of the issues that arise with regard to parallel programming yourself.</p>
            
                <h4 class="t4" id="h25.3.1.1">Resource Access<a class="indexanchor" id="i25_66"/></h4>
                <p class="standard">The first difficulty involves accessing resources. If multiple processes have read-only access to a resource, there won’t be any problem. Things are getting more difficult, however, as soon as write access comes into play. If two processes try to write to a file at the same time, the second process overwrites the changes of the first process in the worst case. Consequently, those changes would be lost then. To solve this problem, a locking mechanism<a class="indexanchor" id="i25_67"/> should be used so that only one process at a time is given write access to a file. A commonly used way to implement such a locking mechanism involves the creation of lock files. If such a file exists, this is a signal to other processes that a resource has been opened exclusively for write accesses from within this process. Node.js can help in this context too. <span class="crossreference "><a href="25_003.html#l25.9">Listing 25.9</a></span> contains source code you can use to open a file for exclusive write access.</p>
                <div class="listing " id="l25.9"><pre><span class="rot">import</span><span class="schwarz"> </span><span class="schwarz">{</span><span class="schwarz"> open </span><span class="schwarz">}</span><span class="schwarz"> </span><span class="rot">from</span><span class="schwarz"> </span><span class="hellblau">'fs'</span><span class="schwarz">;</span><span class="schwarz"><br/></span> <br/><span class="schwarz">open(</span><span class="hellblau">'lock'</span><span class="schwarz">,</span><span class="schwarz"> </span><span class="hellblau">'wx+'</span><span class="schwarz">,</span><span class="schwarz"> </span><span class="schwarz">(</span><span class="schwarz">error</span><span class="schwarz">,</span><span class="schwarz"> fd</span><span class="schwarz">)</span><span class="schwarz"> </span><span class="dunkelblau">=&gt;</span><span class="schwarz"> </span><span class="schwarz">{</span><span class="schwarz"><br/></span>  <span class="rot">if</span><span class="schwarz"> </span><span class="schwarz">(</span><span class="schwarz">error</span><span class="schwarz">)</span><span class="schwarz"> </span><span class="schwarz">{</span><span class="schwarz"><br/></span>    <span class="rot">throw</span><span class="schwarz"> error</span><span class="schwarz">;</span><span class="schwarz"><br/></span>  <span class="schwarz">}</span><span class="schwarz"><br/></span>  <span class="magenta">console</span><span class="schwarz">.log(</span><span class="schwarz">fd</span><span class="schwarz">);</span><span class="schwarz"><br/></span><span class="schwarz">});</span><span class="schwarz"> </span></pre></div>
                <p class="caption "><b>Listing 25.9</b>    
            Opening a File for Exclusive Write Access</p>
                <p class="standard"><a id="p724"/>If you now include this file as a child process and fork this child process twice, the first fork works without problems. The second fork fails with an error message. A similar situation to writing files exists when accessing databases. Again, you must make sure that one thread doesn’t overwrite the changes of another. Most databases lock tables or individual records for parallel write access. However, this doesn’t prevent the data from being overwritten at a later time. In this case, you must provide for the synchronization of the information within your software or have an appropriate conflict resolution ready.</p>
            
            
                <h4 class="t4" id="h25.3.1.2">Multiple Parallel Processes<a class="indexanchor" id="i25_68"/></h4>
                <p class="standard">In modern web applications, it’s not sufficient in most cases to cover only a certain part of the application logic with a separate worker process<a class="indexanchor" id="i25_69"/>. (For more information on the topic of asynchronous programming with Node.js, see <span class="crossreference "><a href="16_001.html#h16">Chapter 16</a></span>.) Instead, in many cases, you need to outsource multiple parts of your application, which can often be parallelized. This constellation involves the problem that you must ensure the source code of your application, which is to be executed after these parallel tasks, is actually not run until all tasks needed for it have been completed. <span class="crossreference "><a href="25_003.html#l25.10">Listing 25.10</a></span> shows a possible solution to this problem. The example is based on the assumption that both child processes send only one message each with the result of the calculation.</p>
                <div class="listing " id="l25.10"><pre><span class="rot">import</span><span class="schwarz"> </span><span class="schwarz">{</span><span class="schwarz"> fork </span><span class="schwarz">}</span><span class="schwarz"> </span><span class="rot">from</span><span class="schwarz"> </span><span class="hellblau">'child_process'</span><span class="schwarz">;</span><span class="schwarz"><br/></span> <br/><span class="rot">const</span><span class="schwarz"> child1 </span><span class="dunkelblau">=</span><span class="schwarz"> </span><span class="schwarz">fork(</span><span class="hellblau">'logic.js'</span><span class="schwarz">);</span><span class="schwarz"><br/></span><span class="rot">const</span><span class="schwarz"> child2 </span><span class="dunkelblau">=</span><span class="schwarz"> </span><span class="schwarz">fork(</span><span class="hellblau">'logic.js'</span><span class="schwarz">);</span><span class="schwarz"><br/></span> <br/><span class="rot">function</span><span class="schwarz"> </span><span class="schwarz">childProcessReceiver(</span><span class="schwarz">child</span><span class="schwarz">)</span><span class="schwarz"> </span><span class="schwarz">{</span><span class="schwarz"><br/></span>  <span class="rot">return</span><span class="schwarz"> </span><span class="rot">new </span><span class="schwarz">Promise((</span><span class="schwarz">resolve</span><span class="schwarz">,</span><span class="schwarz"> reject</span><span class="schwarz">)</span><span class="schwarz"> </span><span class="dunkelblau">=&gt;</span><span class="schwarz"> </span><span class="schwarz">{</span><span class="schwarz"><br/></span>    child<span class="schwarz">.on(</span><span class="hellblau">'message'</span><span class="schwarz">,</span><span class="schwarz"> </span><span class="schwarz">(</span><span class="schwarz">data</span><span class="schwarz">)</span><span class="schwarz"> </span><span class="dunkelblau">=&gt;</span><span class="schwarz"> </span><span class="schwarz">{</span><span class="schwarz"><br/></span>      <span class="schwarz">resolve(</span><span class="schwarz">data</span><span class="schwarz">);</span><span class="schwarz"><br/></span>    <span class="schwarz">});</span><span class="schwarz"><br/></span>    child<span class="schwarz">.on(</span><span class="hellblau">'error'</span><span class="schwarz">,</span><span class="schwarz"> </span><span class="schwarz">(</span><span class="schwarz">error</span><span class="schwarz">)</span><span class="schwarz"> </span><span class="dunkelblau">=&gt;</span><span class="schwarz"> </span><span class="schwarz">{</span><span class="schwarz"><br/></span>      <span class="schwarz">reject(</span><span class="schwarz">error</span><span class="schwarz">);</span><span class="schwarz"><br/></span>    <span class="schwarz">});</span><span class="schwarz"><br/></span>  <span class="schwarz">});</span><span class="schwarz"><br/></span><span class="schwarz">}</span><span class="schwarz"><br/></span> <br/><span class="rot">async</span><span class="schwarz"> </span><span class="rot">function</span><span class="schwarz"> </span><span class="schwarz">handleResults(</span><span class="schwarz">childProcess1</span><span class="schwarz">,</span><span class="schwarz"> childProcess2</span><span class="schwarz">)</span><span class="schwarz"> </span><span class="schwarz">{</span><span class="schwarz"><br/></span>  <span class="rot">const</span><span class="schwarz"> results </span><span class="dunkelblau">=</span><span class="schwarz"> </span><span class="rot">await</span><span class="schwarz"> Promise</span><span class="schwarz">.all([</span><span class="schwarz"><br/></span>    <span class="schwarz">childProcessReceiver(</span><span class="schwarz">childProcess1</span><span class="schwarz">),</span><span class="schwarz"><br/></span>    <span class="schwarz">childProcessReceiver(</span><span class="schwarz">childProcess2</span><span class="schwarz">),</span><span class="schwarz"><br/></span>  <span class="schwarz">]);</span><span class="schwarz"><br/></span> <br/>  <span class="magenta">console</span><span class="schwarz">.log(</span><span class="violett">`The total is: ${results[0] + results[1]}`</span><span class="schwarz">);</span><span class="schwarz"><br/></span><span class="schwarz"><a id="p725"/>}</span><span class="schwarz"><br/></span> <br/><span class="schwarz">handleResults(</span><span class="schwarz">child1</span><span class="schwarz">,</span><span class="schwarz"> child2</span><span class="schwarz">);</span><span class="schwarz"> </span></pre></div>
                <p class="caption "><b>Listing 25.10</b>    
            Merging Parallel Processes (index.js)</p>
                <p class="standard"><span class="crossreference "><a href="25_003.html#l25.10">Listing 25.10</a></span> contains the source code of the entry file named <span class="italic">index.js</span> into an application. In this file, you merge the results of two child processes. The tasks of the child processes can range from generating a random number, as in the example here, to extensive computational logic, depending on the requirements of your application. <span class="crossreference "><a href="25_003.html#l25.11">Listing 25.11</a></span> contains the source code for the two child processes, each of which is to generate a random integer.</p>
                <div class="listing " id="l25.11"><pre>process<span class="schwarz">.send(</span><span class="schwarz">Math</span><span class="schwarz">.floor(</span><span class="schwarz">Math</span><span class="schwarz">.random()</span><span class="schwarz"> </span><span class="dunkelblau">*</span><span class="schwarz"> </span><span class="schwarz">1000));</span><span class="schwarz"> </span></pre></div>
                <p class="caption "><b>Listing 25.11</b>    
            Generating a Random Number in the Child Process (logic.js)</p>
                <p class="standard">In the parent process, you first create the two child processes. Then you implement the <samp class="listingcharacter listingcharacter">childProcessReceiver</samp> function, which accepts a reference to a child process, registers itself on the <samp class="listingcharacter listingcharacter">message</samp> event of the child process, and returns a promise object that is successfully resolved when a message arrives. If an error occurs, that is, the <samp class="listingcharacter listingcharacter">error</samp> event gets triggered, the promise object will be rejected.</p>
                <p class="standard">The <samp class="listingcharacter listingcharacter">handleResults</samp> function gets references to both child processes and uses a combination of <samp class="listingcharacter listingcharacter">Promise.all</samp> and the <samp class="listingcharacter listingcharacter">childProcessReceiver</samp> function to merge the results of both child processes. Finally, you output the total of both random numbers to the console.</p>
                <p class="standard">This example has shown how you can distribute the load in your application. The implementation is still rather simple and subject to significant limitations. For more extensive applications, you should implement an event architecture, streams, or additional libraries such as Reactive Extensions for JavaScript (RxJS).</p>
            
            
                <h4 class="t4" id="h25.3.1.3">Miscellaneous</h4>
                <p class="standard">If you use the <samp class="listingcharacter listingcharacter">child_process</samp> module for the purpose of parallelization in your application, you should make sure to keep the forking of child processes under control<a class="indexanchor" id="i25_70"/>. If too many child processes are created, this will affect your system<a class="indexanchor" id="i25_71"/>. Each child process requires memory and processor computing time. If the resource demands exceed the available resources, your system will slow down, and you won’t benefit at all from the child processes.</p>
                <p class="standard">If you use child processes within your application, you can have individual a child processes once carry out multiple calculations, once a child process has been started. The advantage of this approach is that the child process doesn’t have to be started first. However, this only makes sense if you frequently have similar calculations performed. The Node.js platform provides additional modules for such problems, which you can incorporate into your application. These modules include, among others, the <samp class="listingcharacter listingcharacter">child_<a id="p726"/>process</samp> and the <samp class="listingcharacter listingcharacter">cluster</samp> modules<a class="indexanchor" id="i25_72"/>. In <span class="crossreference "><a href="16_001.html#h16">Chapter 16</a></span>, you’ve already seen a detailed example on this topic and learned about the possibility of outsourcing the load balancing of your server to your operating system.</p>
            
        
        
            <h3 class="t3" id="h25.3.2">25.3.2    Load Balancer<a class="indexanchor" id="i25_73"/></h3>
            <p class="standard">However, there are occasions where you reach the limits of your system when scaling your application. In this case, your only option is to include additional systems to share the load of your system. However, you need to build your application to handle this type of infrastructure. What this means for you in concrete terms is that not every application can be scaled by merely adding another server. Basically, the instances of your application running on the different servers should be as independent as possible and use a common database or other system to synchronize the states. Once you’ve fulfilled these conditions, you’ll need another piece of software to ensure that requests to your application are distributed appropriately among the available servers. There are numerous systems that can perform this task. In the following sections, you’ll get to know two different load balancers: HAProxy and NGINX.</p>
            
                <h4 class="t4" id="h25.3.2.1">HAProxy<a class="indexanchor" id="i25_74"/></h4>
                <p class="standard">You can use HAProxy (<span class="url"><a href="http://haproxy.org/">http://haproxy.org/</a></span>) as a freely available load balancer for applications based on HTTP connections as well as for TCP connections. This software is designed to act as a high-performance interface between your users and your application. In this role, HAProxy can manage tens of thousands of incoming connections. The software is mainly available for Unix systems such as Linux and Solaris. On Windows, HAProxy can also be installed via a few workarounds using Cygwin. The configuration of the load balancer is done by means of a configuration file. <span class="crossreference "><a href="25_003.html#l25.12">Listing 25.12</a></span> contains an excerpt of such a configuration file.</p>
                <div class="listing " id="l25.12"><pre>listen http 192.168.0.1:8080<br/>    mode tcp<br/>    option tcplog<br/>    balance roundrobin<br/>    maxconn 10000<br/>    server web01 192.168.0.2:8080 maxconn 5000<br/>    server web02 192.168.0.3:8080 maxconn 5000 </pre></div>
                <p class="caption "><b>Listing 25.12</b>    
            Configuration of HAProxy</p>
                <p class="standard">The <samp class="listingcharacter listingcharacter">listen</samp> directive allows you to define the proxy server. The two <samp class="listingcharacter listingcharacter">server</samp> specifications indicate the systems to which the requests are forwarded. <samp class="listingcharacter listingcharacter">maxconn</samp> helps you to define how many requests the load balancer will accept. The <samp class="listingcharacter listingcharacter">maxconn</samp> specifications with the respective servers determine how many connections are forwarded to the servers in each case. In the algorithm to be used, you define how HAProxy decides when and <a id="p727"/>which system gets which connection. In <span class="crossreference "><a href="25_003.html#l25.12">Listing 25.12</a></span>, round robin<a class="indexanchor" id="i25_75"/> is used as an algorithm. Here, the requests are distributed evenly among the servers. This algorithm also allows you to weight the different servers. Depending on the weighting, servers are allocated more or fewer requests. If one server fails, the requests are distributed to the remaining servers. This means that the failure of one machine doesn’t impact the overall system. If the machine is available again at a later time, it’s reintegrated and can receive new requests. This architecture provides you with a very high-performance and flexible system with the greatest possible reliability.</p>
                <p class="standard">NGINX represents another system for balancing the load of requests. The following section describes how to proceed when using this system.</p>
            
            
                <h4 class="t4" id="h25.3.2.2">NGINX<a class="indexanchor" id="i25_76"/></h4>
                <p class="standard">NGINX is predominantly known as a lightweight and performant web server. However, this software offers much more than just web server functionality. With NGINX, you can implement a similar infrastructure as you already have with HAProxy, but it’s not as specialized in proxy and load balancing functionality as HAProxy. <span class="crossreference "><a href="25_003.html#l25.13">Listing 25.13</a></span> shows the relevant excerpts from the configuration file of NGINX, which ensure that NGINX is turned into a load balancer.</p>
                <div class="listing " id="l25.13"><pre>http {<br/>    ...<br/>    upstream node_upstream {<br/>        server 192.168.0.2:8080 weight=5;<br/>        server 192.168.0.3:8080;<br/>    }<br/>    ...<br/>    server {<br/>        ...<br/>        location / {<br/>            ...<br/>            proxy_pass http://node_upstream<br/>        }<br/>        ...<br/>    }<br/>} </pre></div>
                <p class="caption "><b>Listing 25.13</b>    
            Configuration of a NGINX Load Balancer</p>
                <p class="standard">For your NGINX instance to become a load balancer, you need the support of a module of NGINX, namely, the <samp class="listingcharacter listingcharacter">HttpProxyModule</samp>. For this purpose, you define an <samp class="listingcharacter listingcharacter">upstream</samp> resource in your configuration file and specify here the servers to which you want to distribute the load. After that, you add the <samp class="listingcharacter listingcharacter">proxy_pass</samp><a class="indexanchor" id="i25_77"/> option to your default location, which gets the name of the <samp class="listingcharacter listingcharacter">upstream</samp> resource as its value. As with HAProxy, you can <a id="p728"/>weigh the different servers. By specifying <samp class="listingcharacter listingcharacter">weight</samp>, which you can see at the first server, you assign a certain weight to a server. Specifying the value <samp class="listingcharacter listingcharacter">5</samp> means that the first server will receive five requests, while the second server will receive only one. As load balancing algorithms, NGINX provides round robin<a class="indexanchor" id="i25_78"/>, least connections<a class="indexanchor" id="i25_79"/>, and IP-Hash, with round robin being the default. With NGINX, as with HAProxy, you can build a very performant infrastructure for your application.</p>
                <p class="standard">Using a load balancer in front of your servers to scale your application means you have to manage your infrastructure by yourself. As a consequence, you need to ensure that the hardware and software for the infrastructure is available. In case of failures, you have to make sure you’ll repair the servers. An alternative to operating the infrastructure in-house is to hand over this responsibility to an external service provider. One concrete way is to move your application to the cloud. In the following section, you’ll see what options you have in that regard.</p>
            
        
        
            <h3 class="t3" id="h25.3.3">25.3.3    Node in the Cloud<a class="indexanchor" id="i25_80"/></h3>
            <p class="standard">The term <span class="italic">cloud</span> is now very commonly used, especially for web applications. However, there is no clear definition for this keyword. For example, cloud can be interpreted as cloud storage, cloud computing, or platform as a service (PaaS)<a class="indexanchor" id="i25_81"/>, where you can access the various manifestations of clouds. There are countless cloud service providers on the market. In this section, you’ll get a brief overview of two of these platforms. One is Heroku, a standalone cloud application platform, and the other is Azure, Microsoft’s cloud platform.</p>
            
                <h4 class="t4" id="h25.3.3.1">Heroku<a class="indexanchor" id="i25_82"/></h4>
                <p class="standard">To deploy your application to the Heroku cloud, you need a helper application called Heroku Toolbelt<a class="indexanchor" id="i25_83"/>. This application must be installed on your system to make the <samp class="listingcharacter listingcharacter">heroku</samp> command-line tool available to you. You can then use this tool to create your Heroku account, which you’ll later use to upload your application to the cloud. (You can find more information and resources on Heroku at <span class="url"><a href="http://www.heroku.com">www.heroku.com</a></span>.) An important prerequisite for Heroku to deploy your application correctly is the existence of a <span class="italic">package.json</span> file, just like you need to create one for a regular npm package. In this file, you must list the dependencies of your application, among other things. You also need a file called <span class="italic">Procfile</span>, which you use to define which command should be used to start your application. <span class="crossreference "><a href="25_003.html#l25.14">Listing 25.14</a></span> shows an example of a <span class="italic">Procfile</span> file.</p>
                <div class="listing " id="l25.14"><pre>web: npm start </pre></div>
                <p class="caption "><b>Listing 25.14</b>    
            Example of a Procfile File</p>
                <p class="standard">The <span class="italic">Procfile</span> file in <span class="crossreference "><a href="25_003.html#l25.14">Listing 25.14</a></span> makes sure that the application is launched on the server via the <samp class="listingcharacter listingcharacter">npm start</samp> command. If your dependencies are installed locally, you can <a id="p729"/>use the <samp class="listingcharacter listingcharacter">foreman start</samp> command to start your application locally. The <samp class="listingcharacter listingcharacter">foreman</samp> command is part of the Heroku Toolbelt application. The next step is to add your application to a Git repository. The two commands shown in <span class="crossreference "><a href="25_003.html#l25.15">Listing 25.15</a></span> allow you to deploy your application to the Heroku cloud.</p>
                <div class="listing " id="l25.15"><pre>$ heroku create<br/>...<br/>$ heroku push heroku master<br/>...<br/>$ heroku ps:scale web=1<br/>$ heroku ps<br/>... <br/>$ heroku open </pre></div>
                <p class="caption "><b>Listing 25.15</b>    
            Deployment to the Heroku Cloud</p>
                <p class="standard">The <samp class="listingcharacter listingcharacter">heroku ps:scale web=1</samp> command enables you to ensure that only one process is started. The <samp class="listingcharacter listingcharacter">heroku ps</samp> command will then show the current state of your application. Finally, you can open your application in the browser via <samp class="listingcharacter listingcharacter">heroku open</samp>.</p>
                <p class="standard">After this very simple introduction to Heroku, the following section describes how you can deploy your Node.js application to the Microsoft Azure cloud.</p>
            
            
                <h4 class="t4" id="h25.3.3.2">Microsoft Azure<a class="indexanchor" id="i25_84"/></h4>
                <p class="standard">Similar to Heroku, you also need an account with Microsoft Azure before you can use the service. For an introduction to the world of Microsoft Azure, you should visit <span class="url"><a href="https://azure.microsoft.com/en-us/">https://azure.microsoft.com/en-us/</a></span>. You can create your account through the Azure Management Portal. The following example is based on the assumption that you have an Express application that can be started using the <samp class="listingcharacter listingcharacter">npm start</samp> command. The first step is to create a ZIP archive of your application. This is done on the Windows Bash using the <samp class="listingcharacter listingcharacter">zip -r webApp.zip .</samp> command. You then create a resource group on the Microsoft Azure shell that acts as a container for your application. You can create that resource group using the <samp class="listingcharacter listingcharacter">az group create -name expressAppGroup -location "West Europe"</samp> command. Next, you create a service plan via the <samp class="listingcharacter listingcharacter">az appservice plan create --name expressAppPlan --resource-group expressAppGroup --sku FREE</samp> command. Finally, you use <samp class="listingcharacter listingcharacter">az webapp create --resource-group expressAppGroup --plan expressAppPlan --name expressApp --runtime " node|14-lts"</samp> to create your web app. Your application is now available at <span class="italic">http://expressApp.azurewebsites.net</span>. You can upload the ZIP file containing your application via <span class="italic">https://expressApp.scm.azurewebsites.net/ZipDeploy</span> and use it to deploy.</p>
                <p class="standard">As you’ve seen from the two examples, it’s possible to bring your Node.js application to the cloud. The platforms support you in these tasks either directly through tools or by means of an online platform.</p>
            
        
    </div><p class="signatur"/>
                    </body>
                </html>